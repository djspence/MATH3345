{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-166d0b0bd7d2633f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Python Activity\n",
    "## Data Wrangling\n",
    "\n",
    "This notebook is designed to acquaint you with some of the data wrangling and transformation tools in the Pandas module of Python. Refer to the content in Chapters 8 and 10 of _**Python for Data Analysis (3rd Ed.)**_ for examples of the type of code you need for these exercises.\n",
    "\n",
    "For EACH exercise:\n",
    "\n",
    "1. Read the description of the task\n",
    "2. Type your solution in the code cell marked ```### YOUR CODE HERE```\n",
    "3. Run your code (fix any issues and re-run if needed)\n",
    "4. Run the TEST CELL that FOLLOWS your code cell. **_DO NOT MODIFY THE TEST CELL._**\n",
    "\n",
    "The output from the TEST CELL will indicate whether you have performed the task correctly. If the result does not say _`Passed!`_ then you should return to your code cell and revise your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "We will start by loading Pandas and other Python libraries needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed in this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tidying Transformations: Gathering (\"Melting\") and Spreading (\"Casting\")\n",
    "\n",
    "Given a data set and a target set of variables, there are at least two common issues that require tidying.\n",
    "\n",
    "> Melting and casting are Wickham's terms from [his original paper on tidying data](http://www.jstatsoft.org/v59/i10/paper). In his more recent writing, [on which this tutorial is based](http://r4ds.had.co.nz/tidy-data.html), he refers to the same operations as _gathering_ and _spreading_.\n",
    "\n",
    "### Melting\n",
    "First, values often appear as columns. The table on the right is an example. To tidy up, you want to turn columns into rows:\n",
    "\n",
    "![Gather example](http://r4ds.had.co.nz/images/tidy-9.png)\n",
    "\n",
    "Because this operation takes columns into rows, making a \"fat\" table more tall and skinny, it is sometimes called _melting_. It is also referred to as 'Gathering' or simply 'Wide to Long' (see textbook). However, the `pandas` operation that performs this function is called `melt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"melting\" the above table includes the following steps:\n",
    "\n",
    "1. Identify the column(s) that will be used as _**ID**_ column(s).  In the above example, this is the `country` column.\n",
    "2. Identify the columns that will provide values for a new _**key**_ column. In the above example, the columns `1999` and `2000` become **values** in a key column called `year`.\n",
    "3. Convert the values _associated_ with the columns identified in step 2 into a new column as well. In this case, the values formerly in columns `1999` and `2000` become the values in the `cases` column.\n",
    "\n",
    "Viewing the above example in the context of a melt, it is common to describe `year` as a new _**key**_ variable and `cases` as the new _**value**_ variable for that key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Write a function called `my_melt` to perform a melt meeting the following specifications:\n",
    "\n",
    "```python\n",
    "    def my_melt(df, id_cols, val_cols, key, value):\n",
    "        ...\n",
    "```\n",
    "\n",
    "It should take the following arguments:\n",
    "- `df`: the input data frame, e.g., `table4` in the example above;\n",
    "- `id_cols`: a list of the column names that serve as ID; e.g., `Country` in example above\n",
    "- `val_cols`: a list of the column names that will serve as values; e.g., column `1999` & `2000` in example  table\n",
    "- `key`: name of the new key variable; e.g., `year` in the example above;\n",
    "- `value`: name of the column to hold the values; e.g., `cases` in the example above\n",
    "\n",
    ">#### NOTES\n",
    ">* By far the easiest way to implement the body of this function is to use the **pandas** `melt` function, and pass it the appropriate parameters. \n",
    ">* The example in the text will get you started with examples of `pd.melt`, but you will need to search for additional documentation. _**HINT:**_ Every argument in your function will need to be passed as the appropriate argument to `pd.melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_melt(df, id_cols, val_cols, key, value):\n",
    "    assert type(df) is pd.DataFrame\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "\n",
    "\n",
    "# You can use the code below to try your function before proceeding to the test cell.\n",
    "df = pd.DataFrame(columns=['Country','Other','1999','2000'],\n",
    "                      data=list(zip(['Afghanistan','Brazil','China'],\n",
    "                                    ['Stuff1','Stuff2','Stuff3'],\n",
    "                                    [745,375,2208],\n",
    "                                    [841,422,3119])))\n",
    "display(df)\n",
    "my_melt(df,['Country','Other'],['1999','2000'],'Year','Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: `melt_test`\n",
    "\n",
    "def tibbles_are_equivalent(A, B):\n",
    "    \"\"\"Given two tidy tables ('tibbles'), returns True iff they are\n",
    "    equivalent.\n",
    "    \"\"\"\n",
    "    Acols = list(A.columns)\n",
    "    Bcols = list(B.columns)\n",
    "    if not len(Acols) == len(Bcols):\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        Z = A.merge(B,on=Acols)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    if not len(A)==len(Z):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "table4a = pd.read_csv('Data/table4a.csv')\n",
    "print(\"\\n=== table4a ===\")\n",
    "display(table4a)\n",
    "\n",
    "m_4a = my_melt(table4a, id_cols = ['country'], val_cols=['1999', '2000'], key='year', value='cases')\n",
    "print(\"=== melt(table4a) ===\")\n",
    "display(m_4a)\n",
    "\n",
    "table4b = pd.read_csv('Data/table4b.csv')\n",
    "print(\"\\n=== table4b ===\")\n",
    "display(table4b)\n",
    "\n",
    "m_4b = my_melt(table4b, id_cols = ['country'], val_cols=['1999', '2000'], key='year', value='population')\n",
    "print(\"=== melt(table4b) ===\")\n",
    "display(m_4b)\n",
    "\n",
    "m_4 = pd.merge(m_4a, m_4b, on=['country', 'year'])\n",
    "print (\"\\n=== inner-join(melt(table4a), melt (table4b)) ===\")\n",
    "display(m_4)\n",
    "\n",
    "m_4['year'] = m_4['year'].apply (int)\n",
    "\n",
    "table1 = pd.read_csv('Data/table1.csv')\n",
    "print (\"=== table1 (target solution) ===\")\n",
    "display(table1)\n",
    "assert tibbles_are_equivalent(table1, m_4)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting (or Spreading)\n",
    "The second most common issue is that an observation might be split across multiple rows. Table 2 is an example. To tidy up, you want to merge rows:\n",
    "\n",
    "![Spread example](http://r4ds.had.co.nz/images/tidy-8.png)\n",
    "\n",
    "This operation is conceptually the opposite of melting, \"re-assembling\" observations from parts; it is sometimes called _casting_. It is also referred to as 'Spreading' or simply 'Long to Wide' (see textbook). However, the `pandas` operation that performs this function is called `pivot`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Write a function called `my_cast` to perform a cast meeting the following specifications:\n",
    "\n",
    "Implement a function to cast a data frame into wide format, given a key column containing new variable names and a value column containing the corresponding values.\n",
    "\n",
    "```python\n",
    "    def my_cast(df, id_cols, key, value):\n",
    "        ...\n",
    "```\n",
    "\n",
    "It should take the following arguments:\n",
    "- `df`: the input data frame; e.g., `table2` in the example above\n",
    "- `id_cols`: a list with the names of the ID columns; e.g., `country` and `year` in the above example\n",
    "- `key`: name of the column containing the key variable; e.g., column `key` in the above example\n",
    "- `value`: name of the column containing the values; e.g., `values` in the above example\n",
    "\n",
    ">#### NOTES\n",
    ">* By far the easiest way to implement the body of this function is to use the **pandas** `pivot` function, and pass it the appropriate parameters. \n",
    ">* The example in the text will get you started with examples of `pd.pivot`, but you will need to search for additional documentation. _**HINT:**_ Every argument in your function will need to be passed as the appropriate argument to `pd.pivot`\n",
    ">* If you use the simplest solution, you may find that your ID columns have been made into the index; this structure will not pass the test, because these columns should actually be part of the dataframe. You can resolve this with code similar to the following:\n",
    "```python\n",
    "                  tibble = tibble.reset_index().rename(columns={\"index\":\"keycols\"}) \n",
    "```\n",
    ">    _This will take all values in the index and put them back into the dataframe as the appropriate columns._\n",
    "\n",
    "Your code cell below contains a partial solution that verifies that the given `key` and `value` columns are actual columns of the input data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def my_cast(df, key, value, join_how='outer'):\n",
    "def my_cast(df, id_cols,key, value):\n",
    "    \"\"\"Casts the input data frame into a tibble,\n",
    "    given the unique ID, key column and value column.\n",
    "    \"\"\"\n",
    "    assert type(df) is pd.DataFrame\n",
    "    assert key in df.columns and value in df.columns  \n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "\n",
    "# You can use the code below to try your function before proceeding to the test cell.\n",
    "t = pd.read_csv('Data/table2.csv')\n",
    "display(t)\n",
    "my_cast(t,['country','year'],'type','count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: `cast_test`\n",
    "\n",
    "table2 = pd.read_csv('Data/table2.csv')\n",
    "print('=== table2 ===')\n",
    "display(table2)\n",
    "\n",
    "print(\"\\n=== tibble2 = my_cast (table2, ['country','year'], 'type', 'count') ===\")\n",
    "tibble2 = my_cast(table2, ['country','year'], 'type', 'count')\n",
    "display(tibble2)\n",
    "\n",
    "assert tibbles_are_equivalent(table1, tibble2)\n",
    "print('\\n(Passed.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READY TO SUBMIT?\n",
    "You've reached the end of this notebook. Be sure to restart and run all cells again to **make sure all cells are working** when they run in order. Then submit your **completed** HTML to the submission  folder for this activity."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
