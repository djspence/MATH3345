{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-166d0b0bd7d2633f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Python Activity\n",
    "## Introduction to Pandas\n",
    "\n",
    "This notebook is designed to acquaint you with the Pandas module in Python. Refer to the content in Chapter 5 of _**Python for Data Analysis (3rd Ed.)**_ for examples of the type of code you need for these exercises.\n",
    "\n",
    "For EACH exercise:\n",
    "\n",
    "1. Read the description of the task\n",
    "2. Type your solution in the code cell marked ```### YOUR CODE HERE```\n",
    "3. Run your code (fix any issues and re-run if needed)\n",
    "4. Run the TEST CELL that FOLLOWS your code cell. **_DO NOT MODIFY THE TEST CELL._**\n",
    "\n",
    "The output from the TEST CELL will indicate whether you have performed the task correctly. If the result does not say _`Passed!`_ then you should return to your code cell and revise your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92648f77b2c73f26",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Pandas: Tidying Data in Python\n",
    "\n",
    "This activity focuses on relational representation referred to as the _tidy_ form of data. This is the same concept that we examined previously using R. \n",
    "\n",
    "You may recall that the idea of tidy data was developed by [Hadley Wickham](http://hadley.nz/), a statistician and author of many R libraries. Much of this notebook is based on his tutorial materials (see below).\n",
    "\n",
    "If you recall what we have studied in [SQL](https://en.wikipedia.org/wiki/SQL), then you may recognize some of the relational data representations that you will encounter in these exercises. However, you may notice some differences, because our main goal will be to extract or prepare data in a way that makes analysis easier.\n",
    "\n",
    "You may find it helpful to also refer to the original materials on which this lab is based:\n",
    "\n",
    "* Wickham's R tutorial on making data tidy: http://r4ds.had.co.nz/tidy-data.html\n",
    "* The slides from a talk by Wickham on the concept: http://vita.had.co.nz/papers/tidy-data-pres.pdf\n",
    "* Wickham's more theoretical paper of \"tidy\" vs. \"untidy\" data: http://www.jstatsoft.org/v59/i10/paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------\n",
    "\n",
    "## Let's Review: What is tidy data?\n",
    "\n",
    "Consider the following data set collected from a survey or study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representation 1.** [Two-way contigency table](https://en.wikipedia.org/wiki/Contingency_table).\n",
    "\n",
    "|            | Registered to Vote | Not Registered |\n",
    "|-----------:|--------:|------------:|\n",
    "| **Male**   |     20    |      5       |\n",
    "| **Female** |     12    |      9       |\n",
    "\n",
    "**Representation 2.** Summary List (as a \"data frame\").\n",
    "\n",
    "| Gender  | Registered to Vote | Count |\n",
    "|:-------:|:--------:|-----:|\n",
    "| Male    | Yes      | 20     |\n",
    "| Male    | No       |  5     |\n",
    "| Female  | Yes      | 12     |\n",
    "| Female  | No       |  9     |\n",
    "\n",
    "These are two entirely equivalent ways of representing the same data. However, each may be suited to a particular task.\n",
    "\n",
    "Also consider this third representation:\n",
    "\n",
    "**Representation 3.** Observation List (as a data frame).\n",
    "\n",
    "| ID | Gender  | Registered to Vote | \n",
    "|:--:|:-------:|:--------:|\n",
    "| 01| Male    | Yes      |\n",
    "| 02| Male    | Yes      |\n",
    "| 03| Male    | No      |\n",
    "| 04| Male    | Yes      |\n",
    "| 05| Male    | No       |\n",
    "| 06| Female  | Yes      |\n",
    "| 07| Female  | No       | \n",
    "| 08| Female  | No       | \n",
    "| 09| Male    | No       |\n",
    "**_...and so on_**\n",
    "\n",
    "The difference between Representations 2 and 3 is that in Representation 3, each individual in the data set is represented in a separate row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition: Tidy datasets.** More specifically, Wickham defines a tidy data set as one that can be organized into a 2-D table such that\n",
    "\n",
    "1. each column represents a _variable_;\n",
    "2. each row represents an _observation_;\n",
    "3. each entry of the table represents a single _value_, which may come from either categorical (discrete) or continuous spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visual schematic of this definition, [as provided by Wickham](http://r4ds.had.co.nz/images/tidy-1.png):\n",
    "\n",
    "![Wickham's illustration of the definition of tidy](http://r4ds.had.co.nz/images/tidy-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This definition appeals to a statistician's intuitive idea of data he or she wishes to analyze. It is also consistent with tasks that seek to establish a functional relationship between some response (output) variable from one or more independent variables.\n",
    "\n",
    "> Note that in computer science and/or machine learning contexts, we might refer to columns as _features_ and individual rows as _data points_ (i.e., each observation is a 'data point'.)\n",
    "\n",
    "**Definition: Tibbles.** If a table is tidy, we will call it a _tidy table_, or _tibble_, for short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas Library\n",
    "\n",
    "Much like the R libraries that facilitate data tidying, Python has the [Pandas](http://pandas.pydata.org/) module, which provides a convenient way to store tibbles. You may notice that the design and API of Pandas's data frames derives from [R's data frames](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html).\n",
    "\n",
    "You may find this introduction to the Pandas module's data structures useful for reference:\n",
    "\n",
    "* https://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
    "\n",
    "We will start by loading Pandas and other Python libraries needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed in this notebook\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "# Ignore this line. It will be used later.\n",
    "SAVE_APPLY = getattr(pd.DataFrame, 'apply')\n",
    "\n",
    "#Display version of pandas\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "We'll start with the famous [Iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). It consists of 50 samples from each of three species of Iris (_Iris setosa_, _Iris virginica_, and _Iris versicolor_). Four features were measured from each sample: the lengths and the widths of the [sepals](https://en.wikipedia.org/wiki/Sepal) and [petals](https://en.wikipedia.org/wiki/Petal).\n",
    "\n",
    "The following code uses Pandas to read and represent this data in a Pandas data frame object, stored in a variable named `irises`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irises = pd.read_csv('Data/iris.csv')\n",
    "print(\"=== Iris data set: {} rows x {} columns. ===\".format(irises.shape[0], irises.shape[1]))\n",
    "display (irises.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "In a Pandas data frame, every column has a name (stored as a string) and all values within the column must have the same primitive type. This fact makes columns different from, for instance, lists.\n",
    "\n",
    "In addition, every row has a special column, called the data frame's _index_. Each index value serves as a name (or ID) for its row. Below, we print the index for the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irises.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** Run each of the following commands (one at a time) to understand what it does. If it's not obvious, try reading the [Pandas documentation](http://pandas.pydata.org/) or going online to get more information. You may also want to try some additional commands to explore more deeply. \n",
    "\n",
    "```python\n",
    "irises.describe()\n",
    "irises['sepal length'].head()\n",
    "irises[[\"sepal length\", \"petal width\"]].head()\n",
    "irises.iloc[5:10]\n",
    "irises[irises[\"sepal length\"] > 5.0]\n",
    "irises[\"sepal length\"].max()\n",
    "irises['species'].unique()\n",
    "irises.sort_values(by=\"sepal length\", ascending=False).head(1)\n",
    "irises.sort_values(by=\"sepal length\", ascending=False).iloc[5:10]\n",
    "irises.sort_values(by=\"sepal length\", ascending=False).loc[5:10]\n",
    "irises['x'] = 3.14\n",
    "irises.rename(columns={'species': 'type'})\n",
    "del irises['x']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE (Use additional code cells if you like)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Use some of what you learned above to create the following results.\n",
    "\n",
    "* Create a dataframe containing only rows for the _'Iris-virginica'_ species, with only the petal length and petal width columns; store the result in a variable called `iris_virginica`\n",
    "* Create a dataframe containing data (all columns) for only those irises with petal length greater than 4, sorted from smallest to largest petal length; store the result in a variable called `long_petals`\n",
    "* Find the mean petal length of all irises of species _'Iris-setosa'_ in the data set; store the result in a variable called `petal_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE (Use additional code cells if you like)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `basics_test`\n",
    "\n",
    "assert set(iris_virginica.columns) == ({'petal length'} | {'petal width'}), \"Result should only have petal length and width columns\"\n",
    "assert len(iris_virginica.iloc[0]) == 2, \"iris_virginica should have 2 columns\"\n",
    "assert len(iris_virginica) == 50, \"iris_virginica should have 50 rows\"\n",
    "assert abs(iris_virginica[\"petal width\"].mean() - 2.026) < 1e-6, \"iris_virginica does not contain the correct data\"\n",
    "\n",
    "assert len(long_petals) == 84, \"long_petals does not have the correct number of rows\"\n",
    "assert len(long_petals.iloc[0] == 5), \"long_petals does not have the correct number of columns\"\n",
    "assert abs(long_petals[\"petal width\"].mean() - 1.77738) <1e-6, \"long_petals does not contain the correct data\"\n",
    "\n",
    "assert abs(petal_mean - 1.462) < 1e-6, \"Mean petal length of setosa species is incorrect.\"\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data frames: Join operations\n",
    "\n",
    "Another useful operation on data frames is [merging](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html).\n",
    "\n",
    "For instance, consider the following two tables, `A` and `B`:\n",
    "\n",
    "| country     | year | cases  |\n",
    "|:------------|-----:|-------:|\n",
    "| Afghanistan | 1999 |    745 |\n",
    "| Brazil      | 1999 |  37737 |\n",
    "| China       | 1999 | 212258 |\n",
    "| Afghanistan | 2000 |   2666 |\n",
    "| Brazil      | 2000 |  80488 |\n",
    "| China       | 2000 | 213766 |\n",
    "\n",
    "| country     | year | population |\n",
    "|:------------|-----:|-----------:|\n",
    "| Afghanistan | 1999 |   19987071 |\n",
    "| Brazil      | 1999 |  172006362 |\n",
    "| China       | 1999 | 1272915272 |\n",
    "| Afghanistan | 2000 |   20595360 |\n",
    "| Brazil      | 2000 |  174504898 |\n",
    "| China       | 2000 | 1280428583 |\n",
    "\n",
    "Suppose we wish to combine these into a single table, `C`:\n",
    "\n",
    "| country     | year | cases  | population |\n",
    "|:------------|-----:|-------:|-----------:|\n",
    "| Afghanistan | 1999 |    745 |   19987071 |\n",
    "| Brazil      | 1999 |  37737 |  172006362 |\n",
    "| China       | 1999 | 212258 | 1272915272 |\n",
    "| Afghanistan | 2000 |   2666 |   20595360 |\n",
    "| Brazil      | 2000 |  80488 |  174504898 |\n",
    "| China       | 2000 | 213766 | 1280428583 |\n",
    "\n",
    "In Pandas, you can perform this merge using the [`.merge()` function](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html):\n",
    "\n",
    "```python\n",
    "C = A.merge (B, on=['country', 'year'])\n",
    "```\n",
    "\n",
    "In this call, the `on=` parameter specifies the list of column names to use to align or \"match\" the two tables, `A` and `B`. By default, `merge()` will only include rows from `A` and `B` where all keys match between the two tables.\n",
    "\n",
    "The following code cells demonstrate this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframes A and B\n",
    "\n",
    "A_csv = \"\"\"country,year,cases\n",
    "Afghanistan,1999,745\n",
    "Brazil,1999,37737\n",
    "China,1999,212258\n",
    "Afghanistan,2000,2666\n",
    "Brazil,2000,80488\n",
    "China,2000,213766\"\"\"\n",
    "\n",
    "B_csv = \"\"\"country,year,population\n",
    "Afghanistan,1999,19987071\n",
    "Brazil,1999,172006362\n",
    "China,1999,1272915272\n",
    "Afghanistan,2000,20595360\n",
    "Brazil,2000,174504898\n",
    "China,2000,1280428583\"\"\"\n",
    "\n",
    "with StringIO(A_csv) as fp:\n",
    "    A = pd.read_csv(fp)\n",
    "\n",
    "with StringIO(B_csv) as fp:\n",
    "    B = pd.read_csv(fp)\n",
    "    \n",
    "print(\"=== A ===\")\n",
    "display(A)\n",
    "\n",
    "print(\"\\n=== B ===\")\n",
    "display(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge A and B\n",
    "\n",
    "C = A.merge(B, on=['country', 'year'])\n",
    "print(\"\\n=== C = merge(A, B) ===\")\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Joins\n",
    "\n",
    "This default behavior of keeping only rows that match both input frames is an example of what relational database systems call an _inner-join_ operation. But there are several other types of joins.\n",
    "\n",
    "- _Inner-join (`A`, `B`)_ (default): Keep only rows of `A` and `B` where the on-keys match in both.\n",
    "- _Outer-join (`A`, `B`)_: Keep all rows of both frames, but merge rows when the on-keys match. For non-matches, fill in missing values with not-a-number (`NaN`) values.\n",
    "- _Left-join (`A`, `B`)_: Keep all rows of `A`. Only merge rows of `B` whose on-keys match `A`.\n",
    "- _Right-join (`A`, `B`)_: Keep all rows of `B`. Only merge rows of `A` whose on-keys match `B`.\n",
    "\n",
    "You can use `merge`'s `how=...` parameter, which takes the (string) values, `'inner`', `'outer'`, `'left'`, and `'right'`. We will use dataframes `D` and `E` (defined below) to practice some of these joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes to practice joins\n",
    "\n",
    "with StringIO(\"\"\"x,y,z\n",
    "bug,1,d\n",
    "rug,2,d\n",
    "lug,3,d\n",
    "mug,4,d\"\"\") as fp:\n",
    "    D = pd.read_csv(fp)\n",
    "print(\"=== D ===\")\n",
    "display(D)\n",
    "\n",
    "with StringIO(\"\"\"x,y,w\n",
    "hug,-1,e\n",
    "smug,-2,e\n",
    "rug,-3,e\n",
    "tug,-4,e\n",
    "bug,1,e\"\"\") as fp:\n",
    "    E = pd.read_csv(fp)\n",
    "print(\"\\n=== E ===\")\n",
    "display(E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** Use dataframes `D` and `E` above to create the following results. Remember that you will need to use `how=` within your `merge` instruction to obtain the correct type of merge.\n",
    "\n",
    "* Joining on columns `x` and `y`, create a dataframe containing only rows of `D` and `E` where columns `x` and `y` match in both dataframes; store the joined result in a variable called `join1`\n",
    "* Joining on columns `x` and `y`, create a dataframe containing all rows of `D` and any data from `E` where columns `x` and `y` match; store the joined result in a variable called `join2`\n",
    "* Joining on columns `x` and `y`, create a dataframe containing all rows of `E` and and data from `D` where columns `x` and `y` match; store the joined result in a variable called `join3`\n",
    "* Joining on columns `x` and `y`, create a dataframe containing all rows of both `D` and `E`, combining those rows where columns `x` and `y` match; store the joined result in a variable called `join4`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE (Use additional code cells if you like)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `join_test`\n",
    "\n",
    "assert set(join1.columns) == ({'x'} | {'y'} | {'z'} | {'w'}), \"Joined result should have columns x, y, z, and w\"\n",
    "assert len(join1.iloc[0]) == 4, \"Joined result should have 4 columns\"\n",
    "assert len(join1) == 1, \"join1 should have 1 row\"\n",
    "assert not join1.isnull().values.any(), \"join1 should have no null values\" \n",
    "\n",
    "assert set(join2.columns) == ({'x'} | {'y'} | {'z'} | {'w'}), \"Joined result should have columns x, y, z, and w\"\n",
    "assert len(join2.iloc[0]) == 4, \"Joined result should have 4 columns\"\n",
    "assert len(join2) == 4, \"join2 should have 4 rows\"\n",
    "assert join2[\"w\"].isnull().sum() == 3, \"join2 should have 3 null values in column w\" \n",
    "assert not join2[\"z\"].isnull().values.any(), \"join2 should NOT have null values in column z\"\n",
    "\n",
    "assert set(join3.columns) == ({'x'} | {'y'} | {'z'} | {'w'}), \"Joined result should have columns x, y, z, and w\"\n",
    "assert len(join3.iloc[0]) == 4, \"Joined result should have 4 columns\"\n",
    "assert len(join3) == 5, \"join3 should have 5 rows\"\n",
    "assert not join3[\"w\"].isnull().values.any(), \"join3 should NOT have null values in column w\" \n",
    "assert join3[\"z\"].isnull().sum() == 4, \"join3 should have 4 null values in column z\"\n",
    "\n",
    "assert set(join4.columns) == ({'x'} | {'y'} | {'z'} | {'w'}), \"Joined result should have columns x, y, z, and w\"\n",
    "assert len(join4.iloc[0]) == 4, \"Joined result should have 4 columns\"\n",
    "assert len(join4) == 8, \"join4 should have 8 rows\"\n",
    "assert join4[\"w\"].isnull().sum() == 3, \"join4 should have 3 null values in column w\" \n",
    "assert join4[\"z\"].isnull().sum() == 4, \"join4 should have 4 null values in column z\"\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply functions to data frames\n",
    "\n",
    "Another useful instruction is `apply()`, which can apply a function to a data frame or to a column of the data frame (called a _series_).\n",
    "\n",
    "For instance, suppose we wish to convert the year column in `C` into an abbrievated two-digit form. The code below will do it. Note that we make a _**copy**_ of `C` so our changes will only be made in the copy, without modifying the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall our dataframe C\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to convert a 4-digit numeric year to a 2-digit year as a string\n",
    "\n",
    "The function below will take the last 2 digits of the year and use them to create a string that starts with an apostrophe.  For instance, from the year 2024, the function would return **'24**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year2d (y):\n",
    "    return \"'{:02d}\".format(y % 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below, we try the function on a couple of specific years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2d(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2d(2007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `apply` to apply this function to an entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = C.copy() # If you do not use copy function the original data frame is modified\n",
    "\n",
    "G['year'] = G['year'].apply(year2d)\n",
    "display(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another option: Anonymous functions\n",
    "\n",
    "If the function you want to apply is not needed anywhere else, you can define it directly inside the `apply` command as shown below. Functions defined this way are also called _lambda_ functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = C.copy() # If you do not use copy function the original data frame is modified\n",
    "\n",
    "G['year'] = G['year'].apply(lambda x: \"'{:02d}\".format(x % 100))\n",
    "display(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.** Suppose you wish to compute two new columns:\n",
    "* the _prevalence_, which is the ratio of cases to the population\n",
    "* the prevalence _percentage_, which is the prevalence expressed as a percentage rounded to 4 digits past the decimal, and using the **%** symbol.\n",
    "\n",
    "For the first row in the dataframe (Afghanistan 1999), the prevalence should be $\\frac{745}{19987071} \\approx 0.000037$. Expressed as a percentage, it should appear as **0.0037%**.\n",
    "\n",
    "You are required to use `apply` in your solution. Feel free to consult the example above, the text, or the [documentation for apply()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html) for more help.\n",
    "\n",
    "Implement your solution in a function, `calc_prevalence(G)`, which given `G` returns a **new copy** `H` that has columns named `'prevalence'` and `'percentage'` holding the correctly computed and formatted prevalence and percentage values.\n",
    "\n",
    "> **Note 1.** The emphasis on \"new copy\" is there to remind you that your function should *not* modify the input dataframe, `G`.\n",
    "\n",
    "> **Note 2.** In a previous example, we used a format string of `02d` to format a decimal number; in this exercise, you will need a format string of `0.4f` to format the floating point number to 4 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prevalence(G):\n",
    "    assert 'cases' in G.columns and 'population' in G.columns\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `prevalence_test`\n",
    "\n",
    "G_copy = G.copy()\n",
    "H = calc_prevalence(G)\n",
    "display(H) # Displayed `H` should have a 'prevalence' column\n",
    "\n",
    "assert (G == G_copy).all().all(), \"Did your function modify G? It shouldn't...\"\n",
    "assert set(H.columns) == (set(G.columns) | {'prevalence'} | {'percentage'}), \"Check `H` again: it should have the same columns as `G` plus 2 new columns.\"\n",
    "\n",
    "assert (abs(H['prevalence'][0] - .000037) < 1e-6), \"One or more prevalence values is incorrect.\"\n",
    "assert (abs(H['prevalence'][5] - .000167) < 1e-6), \"One or more prevalence values is incorrect.\"\n",
    "assert (H['percentage'][0] == '0.0037%'), \"At least one percentage value is incorrect.\"\n",
    "assert (H['percentage'][5] == '0.0167%'), \"At least one percentage value is incorrect.\"\n",
    "\n",
    "print(\"Testing use of `apply()`...\")\n",
    "\n",
    "# Tests that you actually used `apply()` in your function:\n",
    "def apply_fail():\n",
    "    raise ValueError(\"Did not find `apply()` in your solution.\")\n",
    "    \n",
    "setattr(pd.DataFrame, 'apply', apply_fail)\n",
    "try:\n",
    "    calc_prevalence(G)\n",
    "except (ValueError, TypeError):\n",
    "    print(\"You used `apply()` in your solution.\")\n",
    "else:\n",
    "    assert False, \"Did not find `apply()` in your solution.\"\n",
    "finally:\n",
    "    setattr(pd.DataFrame, 'apply', SAVE_APPLY)\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READY TO SUBMIT?\n",
    "You've reached the end of this notebook. Be sure to restart and run all cells again to **make sure all cells are working** when they run in order. Then submit your **completed** HTML to the submission  folder for this activity."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
